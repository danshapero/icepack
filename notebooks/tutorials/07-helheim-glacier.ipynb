{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helheim Glacier\n",
    "\n",
    "In this demo we'll look at Helheim Glacier in southeast Greenland.\n",
    "Helheim is one of the bigger glaciers draining the Greenland Ice Sheet by mass flux along with Jakobshavn, Kangerdlugssuaq, Petermann, and the Northeast Greenland Ice Stream.\n",
    "Much of the procedure for working with real data should be familiar from the demo on [inverse problems](https://icepack.github.io/icepack.demo.04-ice-shelf-inverse.html), where we inferred the fluidity of the Larsen C Ice Shelf in the Antarctic Peninsula.\n",
    "Here we'll use many of the same techniques, only instead of inferring the fluidity, we'll look at the friction coefficient for glacier sliding over the underlying bedrock.\n",
    "In the following, we'll assume that ice flow is by Weertman sliding:\n",
    "\n",
    "$$\\tau_b = -C|u|^{\\frac{1}{m} - 1}u,$$\n",
    "\n",
    "where $\\tau_b$ is the basal shear stress, $u$ is the sliding velocity, $m \\approx 3$ is the friction exponent, and $C$ is the friction coefficient.\n",
    "First, we'll estimate the friction coefficient using a 2D, depth-averaged model.\n",
    "Then we'll use this solution as an initial guess using the 3D hybrid model that we showed in [this demo](https://icepack.github.io/icepack.demo.05-hybrid-ice-stream.html) for a synthetic ice stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "\n",
    "Loading in the mesh and input data should be mostly familiar from the previous demos on Larsen C.\n",
    "We'll be using different data sets since we're looking at Greenland rather than Antarctica this time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import icepack\n",
    "outline_filename = icepack.datasets.fetch_outline('helheim')\n",
    "with open(outline_filename, 'r') as outline_file:\n",
    "    outline = geojson.load(outline_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll calculate a bounding box around the outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xmin, ymin, xmax, ymax = np.inf, np.inf, -np.inf, -np.inf\n",
    "δ = 5e3\n",
    "for feature in outline['features']:\n",
    "    for line_string in feature['geometry']['coordinates']:\n",
    "        xs = np.array(line_string)\n",
    "        x, y = xs[:, 0], xs[:, 1]\n",
    "        xmin, ymin = min(xmin, x.min() - δ), min(ymin, y.min() - δ)\n",
    "        xmax, ymax = max(xmax, x.max() + δ), max(ymax, y.max() + δ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did for Larsen, we'll visualize everything on top of a satellite image mosaic of Greenland.\n",
    "The official reason to do this is that it helps us to make sure that all the coordinate systems make sense, and the actual reason is that we just want to make prettier plots.\n",
    "Once again we'll need to do a windowed read because we only care about the area around Helheim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import icepack.plot\n",
    "image_filename = icepack.datasets.fetch_mosaic_of_greenland()\n",
    "image_file = rasterio.open(image_filename, 'r')\n",
    "\n",
    "height, width = image_file.height, image_file.width\n",
    "transform = image_file.transform\n",
    "window = rasterio.windows.from_bounds(\n",
    "    left=xmin, bottom=ymin, right=xmax, top=ymax,\n",
    "    width=width, height=height, transform=transform\n",
    ")\n",
    "\n",
    "image = image_file.read(indexes=1, window=window, masked=True)\n",
    "\n",
    "def subplots(*args, **kwargs):\n",
    "    fig, axes = icepack.plot.subplots()\n",
    "    xmin, ymin, xmax, ymax = rasterio.windows.bounds(window, transform)\n",
    "    axes.imshow(\n",
    "        image,\n",
    "        cmap='Greys_r',\n",
    "        vmin=8e3,\n",
    "        vmax=16.38e3,\n",
    "        extent=(xmin, xmax, ymin, ymax)\n",
    "    )\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll turn the shape file of the outline into the input format for gmsh and generate a mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = icepack.meshing.collection_to_geo(outline, lcar=5e3)\n",
    "with open('helheim.geo', 'w') as geo_file:\n",
    "    geo_file.write(geometry.get_code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gmsh -2 -format msh2 -v 2 -o helheim.msh helheim.geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial mesh that we've generated is pretty coarse, so to get finer resolution we'll create a hierarchy of refined meshes.\n",
    "In our case the mesh hierarchy will only go one level deep, so each triangle has been cut into four similar triangles.\n",
    "Where possible, it's best to start with the coarsest mesh and refine up to the level you need; you can always make a small problem bigger, but it's hard to make a big problem smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firedrake\n",
    "mesh = firedrake.Mesh('helheim.msh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "kwargs = {\n",
    "    'interior_kw': {'linewidth': 0.1},\n",
    "    'boundary_kw': {'linewidth': 2}\n",
    "}\n",
    "icepack.plot.triplot(mesh, axes=axes, **kwargs)\n",
    "axes.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start loading in all the observational data and interpolating it to the function spaces we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness_filename = icepack.datasets.fetch_bedmachine_greenland()\n",
    "thickness = rasterio.open(f'netcdf:{thickness_filename}:thickness', 'r')\n",
    "surface = rasterio.open(f'netcdf:{thickness_filename}:surface', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "Q = firedrake.FunctionSpace(mesh, 'CG', degree)\n",
    "h_obs = icepack.interpolate(thickness, Q)\n",
    "s_obs = icepack.interpolate(surface, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import inner, grad, dx\n",
    "def smooth(q_obs, α):\n",
    "    q = q_obs.copy(deepcopy=True)\n",
    "    J = 0.5 * ((q - q_obs)**2 + α**2 * inner(grad(q), grad(q))) * dx\n",
    "    F = firedrake.derivative(J, q)\n",
    "    firedrake.solve(F == 0, q)\n",
    "    return q\n",
    "\n",
    "α = firedrake.Constant(2e3)\n",
    "h = smooth(h_obs, α)\n",
    "s = smooth(s_obs, α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "colors = icepack.plot.tripcolor(h, axes=axes)\n",
    "fig.colorbar(colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "colors = icepack.plot.tripcolor(s, axes=axes)\n",
    "fig.colorbar(colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_filenames = icepack.datasets.fetch_measures_greenland()\n",
    "velocity_dict = {\n",
    "    key: [f for f in velocity_filenames if key in f][0]\n",
    "    for key in ['vx', 'vy', 'ex', 'ey']\n",
    "}\n",
    "vx = rasterio.open(velocity_dict['vx'], 'r')\n",
    "vy = rasterio.open(velocity_dict['vy'], 'r')\n",
    "ex = rasterio.open(velocity_dict['ex'], 'r')\n",
    "ey = rasterio.open(velocity_dict['ey'], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = firedrake.VectorFunctionSpace(mesh, 'CG', degree)\n",
    "u_obs = icepack.interpolate((vx, vy), V)\n",
    "σx = icepack.interpolate(ex, Q)\n",
    "σy = icepack.interpolate(ey, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import min_value\n",
    "σx = firedrake.interpolate(min_value(200, abs(σx)), Q)\n",
    "σy = firedrake.interpolate(min_value(200, abs(σy)), Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "σx.dat.data_ro[:].min()\n",
    "σy.dat.data_ro[:].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "σ = firedrake.interpolate(firedrake.sqrt(σx**2 + σy**2), Q)\n",
    "colors = icepack.plot.tripcolor(σ, vmax=50, axes=axes)\n",
    "fig.colorbar(colors);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded in the ice thickness and surface elevation, we'll calculate the gravitational driving stress\n",
    "\n",
    "$$\\tau_d = -\\rho_Igh\\nabla s.$$\n",
    "\n",
    "The gravitational driving stress is in balance with internal viscous stresses and with basal stress.\n",
    "By knowing roughly what the magnitudes of the driving stress and the velocity are, we can get a better idea of what a reasonable starting value of the friction coefficient should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icepack.constants import ice_density as ρ_I, gravity as g\n",
    "τ = firedrake.project(-ρ_I * g * h * grad(s), V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "colors = icepack.plot.tripcolor(τ, vmax=0.5, axes=axes)\n",
    "fig.colorbar(colors, label='megapascals');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the inverse problem, we'll assume that the basal shear stress takes up half of the driving stress.\n",
    "This is a totally ad hoc assumption and it's not obvious a priori that this is going to give us reasonable values of the ice velocity.\n",
    "Nonetheless, it happens to work well enough as a starting point.\n",
    "We'll also need to re-parameterize the basal shear stress in terms of some auxiliary variable $q$ in order to guarantee that the friction coefficient is strictly positive.\n",
    "In the following, we'll use\n",
    "\n",
    "$$\\tau_b = -\\frac{\\tau_0}{u_0^{1/m}}e^{-q}|u|^{\\frac{1}{m} - 1}u$$\n",
    "\n",
    "where $\\tau_0$ and $u_0$ are the average magnitudes of the driving stress and speed respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import exp, ln, sqrt, assemble\n",
    "from icepack.constants import weertman_sliding_law as m\n",
    "import icepack.models.friction\n",
    "\n",
    "u = u_obs.copy(deepcopy=True)\n",
    "speed = sqrt(inner(u, u))\n",
    "stress = sqrt(inner(τ, τ))\n",
    "\n",
    "area = assemble(firedrake.Constant(1) * dx(mesh))\n",
    "speed_avg = assemble(speed * dx) / area\n",
    "stress_avg = assemble(stress * dx) / area\n",
    "\n",
    "print(f'Average speed:  {speed_avg:6.1f} meters / year')\n",
    "print(f'Average stress: {1e3 * stress_avg:6.1f} kilopascals')\n",
    "\n",
    "fraction = 0.5\n",
    "C = fraction * stress / speed**(1/m)\n",
    "q = firedrake.interpolate(-ln(speed_avg**(1/m) * C / stress_avg), Q)\n",
    "\n",
    "def bed_friction(**kwargs):\n",
    "    u, q = map(kwargs.get, ('velocity', 'log_friction'))\n",
    "    \n",
    "    C = stress_avg / speed_avg**(1/m) * exp(-q)\n",
    "    return icepack.models.friction.bed_friction(velocity=u, friction=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll assume that the ice is at a constant -13C.\n",
    "We'll revisit this assumption using a heat flow model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = firedrake.Constant(260.)\n",
    "A = icepack.rate_factor(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_model = icepack.models.IceStream(friction=bed_friction)\n",
    "opts = {\n",
    "    'dirichlet_ids': [1, 2, 4, 5, 6],\n",
    "    'diagnostic_solver_parameters': {'max_iterations': 100},\n",
    "}\n",
    "flow_solver = icepack.solvers.FlowSolver(flow_model, **opts)\n",
    "u = flow_solver.diagnostic_solve(\n",
    "    velocity=u_obs, \n",
    "    thickness=h, \n",
    "    surface=s, \n",
    "    fluidity=A, \n",
    "    log_friction=q\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "contours = icepack.plot.tricontourf(u, axes=axes)\n",
    "fig.colorbar(contours, label='meters / year');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring the friction\n",
    "\n",
    "Next we'll apply a similar procedure as the first demo on inverse problems to back out the friction coefficient.\n",
    "The first ingredient is to define the objective and regularization functionals.\n",
    "Rather than use a least-squares type functional to measure the model-data misfit, we'll include a fudge factor that makes the fitting procedure taper off at large misfit values.\n",
    "When the observational data are not actually normally distributed, least-squares fitting can focus too much on outlier data points and, in so doing, spoil the overall result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ϵ = firedrake.Constant(10.0)\n",
    "def objective(u):\n",
    "    δu = u - u_obs\n",
    "    χ2 = (δu[0] / σx)**2 + (δu[1] / σy)**2\n",
    "    return (sqrt(χ2 + ϵ**2) - ϵ) * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularization functional is exactly as before.\n",
    "We're more interested in using this demo to explore 3D flow and heat transport, so it's not essential to resolve the basal shear stress down to the most minute details.\n",
    "As a consequence we can get away with using a fairly large regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Φ = firedrake.Constant(1)\n",
    "L = firedrake.Constant(5e3)\n",
    "def regularization(q):\n",
    "    return 0.5 * (L / Φ)**2 * inner(grad(q), grad(q)) * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formulation of the inverse problem is very similar to what we saw in the previous tutorial for the Larsen ice shelf, but we have to pass in a few extra fields to the diagnostic solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = icepack.inverse.InverseProblem(\n",
    "    model=flow_model,\n",
    "    objective=objective,\n",
    "    regularization=regularization,\n",
    "    state_name='velocity',\n",
    "    state=u,\n",
    "    parameter_name='log_friction',\n",
    "    parameter=q,\n",
    "    solver_kwargs=opts,\n",
    "    diagnostic_solve_kwargs={\n",
    "        'thickness': h,\n",
    "        'surface': s,\n",
    "        'fluidity': A\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'form_compiler_parameters': {'quadrature_degree': 2 * degree + 1}}\n",
    "def callback(solver):\n",
    "    dJ = solver.gradient\n",
    "    q = solver.search_direction\n",
    "    dJ_dq = firedrake.action(dJ, q)\n",
    "    Δ = firedrake.assemble(dJ_dq, **parameters)\n",
    "\n",
    "    E = firedrake.assemble(solver.objective)\n",
    "    R = firedrake.assemble(solver.regularization)\n",
    "    print(f'{E / area:g}, {R / area:g}, {Δ / area:g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test case is more challenging for the inverse solver than the example we used to demonstrate how the inverse solver works in the first place.\n",
    "We'll need to increase the maximum number of iterations of the conjugate gradient algorithm in order to guarantee that the linear solver for the search direction will actually converge.\n",
    "To do this, we'll pass a value for the keyword argument `'search_max_iterations'` to the inverse solver.\n",
    "Steps like this one are often necessary for especially challenging problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = icepack.inverse.GaussNewtonSolver(\n",
    "    problem,\n",
    "    callback,\n",
    "    search_tolerance=1e-10,\n",
    "    search_max_iterations=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, as a sanity check we'll plot the initial search direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "ϕ = solver.search_direction\n",
    "colors = icepack.plot.tripcolor(ϕ, cmap='RdBu', axes=axes)\n",
    "fig.colorbar(colors);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descending along this direction will reduce the basal shear stress along the main trunk of the glacier, which makes sense given that outlet glaciers tend to be found where weak sediments facilitate fast sliding.\n",
    "Now let's go get a coffee and wait for the solver to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = solver.solve(\n",
    "    rtol=0.0,\n",
    "    atol=0.0,\n",
    "    etol=1e-4,\n",
    "    max_iterations=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "q = solver.parameter\n",
    "colors = icepack.plot.tripcolor(\n",
    "    q, vmin=-5, vmax=+5, cmap='bwr', axes=axes\n",
    ")\n",
    "fig.colorbar(colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = solver.state\n",
    "\n",
    "C = stress_avg / speed_avg**(1/m) * exp(-q)\n",
    "U = sqrt(inner(u, u))\n",
    "τ_b = firedrake.interpolate(C * U**(1/m), Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "colors = icepack.plot.tripcolor(\n",
    "    τ_b, vmin=0, vmax=0.5, axes=axes\n",
    ")\n",
    "fig.colorbar(colors, label='megapascals');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ma as ma\n",
    "\n",
    "δx, δy = 500.0, 500.0\n",
    "nx = int(np.floor((xmax - xmin) / δx))\n",
    "ny = int(np.floor((ymax - ymin) / δy))\n",
    "gridded_stress = np.zeros((ny, nx))\n",
    "\n",
    "for i in range(ny):\n",
    "    y = ymax - δy * i\n",
    "    for j in range(nx):\n",
    "        x = xmin + δx * j\n",
    "        try:\n",
    "            gridded_stress[i, j] = 1e3 * τ_b.at((x, y), tolerance=1e-10)\n",
    "        except firedrake.PointNotInDomainError:\n",
    "            gridded_stress[i, j] = np.nan\n",
    "\n",
    "gridded_stress = ma.masked_invalid(gridded_stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = rasterio.transform.from_origin(xmin, ymax, δx, δy)\n",
    "profile = {\n",
    "    'driver': 'GTiff',\n",
    "    'height': ny,\n",
    "    'width': nx,\n",
    "    'count': 1,\n",
    "    'dtype': np.float64,\n",
    "    'crs': thickness.crs,\n",
    "    'transform': transform,\n",
    "}\n",
    "with rasterio.open('helheim-basal-shear.tif', 'w', **profile) as output_file:\n",
    "    output_file.write(gridded_stress, indexes=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "firedrake"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
