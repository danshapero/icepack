{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assimilating sparse data\n",
    "\n",
    "In this demo, we'll look once again at estimating the fluidity coefficient $A$ in Glen's flow law\n",
    "\n",
    "$$\\dot\\varepsilon = A\\tau^3$$\n",
    "\n",
    "from observational data for the Larsen Ice Shelf.\n",
    "The [previous tutorial](https://icepack.github.io/notebooks/tutorials/05-ice-shelf-inverse/) showed how to solve statistical estimation problems.\n",
    "Here we'll explore how to regularize those estimation problems.\n",
    "We'll again use the reparameterization trick of inferring the field $\\theta$ in\n",
    "\n",
    "$$A = A_0e^\\theta$$\n",
    "\n",
    "in order to guarantee that the fluidity coefficient is positive.\n",
    "Before, we used the regularization functional\n",
    "\n",
    "$$R(\\theta) = \\frac{L^2}{2\\Theta^2}\\int_\\Omega|\\nabla \\theta|^2\\mathrm dx.$$\n",
    "\n",
    "This functional penalizes sharp gradients in the inferred field.\n",
    "For some problems, however, we might want to instead penalize the *curvature* or the second derivative of the inferred field instead:\n",
    "\n",
    "$$R(\\theta) = \\frac{L^4}{2\\Theta^2}\\int_\\Omega|\\nabla^2\\theta|^2\\mathrm dx.$$\n",
    "\n",
    "Note how we have a factor of $L^4$ in order to get the units right now instead of $L^2$.\n",
    "But there's a problem.\n",
    "Say we were using a conventional piecewise linear finite element basis.\n",
    "These functions are differentiable, but their derivatives are discontinuous across cell boundaries.\n",
    "We can discretize problems involving first but not second or higher-order derivatives.\n",
    "There are a few ways we can dig ourselves out.\n",
    "Here we'll show one approach -- using an additional field to represent the curvature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "\n",
    "The input data are the same as from the previous demo on inferring the fluidity of the Larsen Ice Shelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import firedrake\n",
    "import icepack\n",
    "\n",
    "outline_filename = icepack.datasets.fetch_outline(\"larsen-2015\")\n",
    "with open(outline_filename, \"r\") as outline_file:\n",
    "    outline = geojson.load(outline_file)\n",
    "\n",
    "icepack.meshing.collection_to_gmsh(outline).write(\"larsen.msh\")\n",
    "mesh = firedrake.Mesh(\"larsen.msh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is the same boilerplate as in the previous tutorial for plotting simulation results on top of the mosaic of Antarctica image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import icepack.plot\n",
    "\n",
    "coords = np.array(list(geojson.utils.coords(outline)))\n",
    "δ = 5e3\n",
    "xmin, xmax = coords[:, 0].min() - δ, coords[:, 0].max() + δ\n",
    "ymin, ymax = coords[:, 1].min() - δ, coords[:, 1].max() + δ\n",
    "\n",
    "image_filename = icepack.datasets.fetch_mosaic_of_antarctica()\n",
    "with rasterio.open(image_filename, \"r\") as image_file:\n",
    "    image_window = rasterio.windows.from_bounds(\n",
    "        left=xmin,\n",
    "        bottom=ymin,\n",
    "        right=xmax,\n",
    "        top=ymax,\n",
    "        transform=image_file.transform,\n",
    "    )\n",
    "    image = image_file.read(indexes=1, window=image_window, masked=True)\n",
    "\n",
    "\n",
    "def subplots(*args, **kwargs):\n",
    "    fig, axes = icepack.plot.subplots(*args, **kwargs)\n",
    "    xmin, ymin, xmax, ymax = rasterio.windows.bounds(\n",
    "        image_window, image_file.transform\n",
    "    )\n",
    "    kw = {\n",
    "        \"extent\": (xmin, xmax, ymin, ymax),\n",
    "        \"cmap\": \"Greys_r\",\n",
    "        \"vmin\": 12e3,\n",
    "        \"vmax\": 16.38e3,\n",
    "    }\n",
    "    try:\n",
    "        axes.imshow(image, **kw)\n",
    "    except AttributeError:\n",
    "        for ax in axes:\n",
    "            ax.imshow(image, **kw)\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "axes.set_xlabel(\"meters\")\n",
    "kwargs = {\n",
    "    \"interior_kw\": {\"linewidth\": 0.25},\n",
    "    \"boundary_kw\": {\"linewidth\": 2},\n",
    "}\n",
    "firedrake.triplot(mesh, axes=axes, **kwargs)\n",
    "axes.legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the previous demos, we'll apply a smoothing filter to the thickness, which is necessary to get a reasonable driving stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "from firedrake import assemble, Constant, avg, jump, dot, inner, grad, dx, ds, dS\n",
    "\n",
    "thickness_filename = icepack.datasets.fetch_bedmachine_antarctica()\n",
    "thickness = xarray.open_dataset(thickness_filename)[\"thickness\"]\n",
    "\n",
    "Q = firedrake.FunctionSpace(mesh, family=\"CG\", degree=2)\n",
    "h0 = icepack.interpolate(thickness, Q)\n",
    "\n",
    "h = h0.copy(deepcopy=True)\n",
    "α = Constant(2e3)\n",
    "J = 0.5 * ((h - h0) ** 2 + α ** 2 * inner(grad(h), grad(h))) * dx\n",
    "F = firedrake.derivative(J, h)\n",
    "firedrake.solve(F == 0, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the velocity data and uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_filename = icepack.datasets.fetch_measures_antarctica()\n",
    "velocity_dataset = xarray.open_dataset(velocity_filename)\n",
    "vx = velocity_dataset[\"VX\"]\n",
    "vy = velocity_dataset[\"VY\"]\n",
    "errx = velocity_dataset[\"ERRX\"]\n",
    "erry = velocity_dataset[\"ERRY\"]\n",
    "\n",
    "V = firedrake.VectorFunctionSpace(mesh, family=\"CG\", degree=2)\n",
    "u_obs = icepack.interpolate((vx, vy), V)\n",
    "σx = icepack.interpolate(errx, Q)\n",
    "σy = icepack.interpolate(erry, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where things start to get different.\n",
    "Before, we took the fluidity parameter $\\theta$ to live in some scalar function space.\n",
    "Here we'll instead work with *both* the fluidity and an additional variable $\\kappa$ for curvature.\n",
    "The constraint between the two fields is that\n",
    "$$\\kappa = \\nabla^2\\theta.$$\n",
    "In order to simultaneously infer both fields, we need to make a function space that will store both.\n",
    "\n",
    "We'll use the same value initial guess for $\\theta$ as in the second demo -- a constant fluidity assuming a temperature of -13C.\n",
    "This makes the initial curvature equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Σ = firedrake.FunctionSpace(mesh, \"HHJ\", degree=1)\n",
    "Z = Q * Σ\n",
    "z = firedrake.Function(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's going to be another difference in how we define the viscosity function.\n",
    "Before, we took in the logarithm of the fluidity as a keyword argument.\n",
    "Now the fluidity and its curvature come packaged together.\n",
    "The method `.split` will pull them apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Constant(260)\n",
    "A0 = icepack.rate_factor(T)\n",
    "\n",
    "def viscosity(**kwargs):\n",
    "    u = kwargs[\"velocity\"]\n",
    "    h = kwargs[\"thickness\"]\n",
    "    z = kwargs[\"log_fluidity_curvature\"]\n",
    "    θ, κ = firedrake.split(z)\n",
    "\n",
    "    A = A0 * firedrake.exp(θ)\n",
    "    return icepack.models.viscosity.viscosity_depth_averaged(\n",
    "        velocity=u, thickness=h, fluidity=A\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup of the model is the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = icepack.models.IceShelf(viscosity=viscosity)\n",
    "opts = {\n",
    "    \"dirichlet_ids\": [2, 4, 5, 6, 7, 8, 9],\n",
    "}\n",
    "solver = icepack.solvers.FlowSolver(model, **opts)\n",
    "\n",
    "u = solver.diagnostic_solve(\n",
    "    velocity=u_obs,\n",
    "    thickness=h,\n",
    "    log_fluidity_curvature=z,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring the fluidity\n",
    "\n",
    "There are four parts that go into an inverse problem:\n",
    "\n",
    "* a physics model\n",
    "* an initial guess for the parameter and state\n",
    "* an error metric\n",
    "* a smoothness metric\n",
    "\n",
    "We already have the physics model and some initial guesses.\n",
    "The physics are wrapped up in the Python function `simulation` defined below; we'll pass this function when we create the inverse problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(z):\n",
    "    return solver.diagnostic_solve(\n",
    "        velocity=u_obs, thickness=h, log_fluidity_curvature=z\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ice shelf is so large, we're going to want to scale some of our output quantities of interest by the area of the shelf.\n",
    "This will make everything into nice dimensionless numbers, rather than on the order of $10{}^{10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = assemble(Constant(1.0) * dx(mesh))\n",
    "Ω = Constant(area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to write a pair of Python functions that will create the model-data misfit functional and the regularization functional.\n",
    "The key difference here is in how we create the regularization functional $R$.\n",
    "This will encode both the penalty on high curvature as well as the constraint that $\\kappa$ really is the curvature of $\\theta$:\n",
    "$$R = \\frac{L^4}{|\\Omega|}\\int_\\Omega\\left(\\frac{1}{2}|\\kappa^2| - \\kappa :\\nabla^2\\theta\\right)dx.$$\n",
    "This expression would be enough if the finite element basis that we used for $\\theta$ had enough derivatives, which it doesn't.\n",
    "What makes HHJ elements for the curvature so convenient is that there are only a couple of extra terms to fix this problem.\n",
    "These involve jumps in the normal derivative of $\\theta$.\n",
    "What they don't involve is funny mesh-dependent constants that you have to tweak.\n",
    "The correction terms are:\n",
    "$$\\ldots + \\sum_\\gamma\\int_\\gamma \\text{avg}(\\nu\\cdot\\kappa\\nu)\\cdot \\text{jump}(\\nabla\\theta\\cdot\\nu)\\,d\\gamma$$\n",
    "where the sum is over all edges of the mesh.\n",
    "You can read more about HHJ elements and how to derive these correction terms [here](https://shapero.xyz/posts/plate-theory/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_functional(u):\n",
    "    δu = u - u_obs\n",
    "    return 0.5 / Ω * ((δu[0] / σx)**2 + (δu[1] / σy)**2) * dx\n",
    "\n",
    "\n",
    "def regularization(z):\n",
    "    Θ = Constant(1.)\n",
    "    L = Constant(125.0)\n",
    "    Λ = L**4 / Θ**2 / Ω\n",
    "\n",
    "    θ, κ = firedrake.split(z)\n",
    "    ν = firedrake.FacetNormal(mesh)\n",
    "    R_1 = (0.5 * inner(κ, κ) - inner(κ, grad(grad(θ)))) * dx\n",
    "    κ_νν = inner(ν, dot(κ, ν))\n",
    "    R_2 = avg(κ_νν) * jump(grad(θ), ν) * dS\n",
    "    R_3 = κ_νν * inner(grad(θ), ν) * ds\n",
    "\n",
    "    return L**4 / (Θ**2 * Ω) * (R_1 + R_2 + R_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create create a `StatisticsProblem` object.\n",
    "To specify the problem, we need to give it a procedure for running the simulation, another procedure for evaluating how good our guess is, and an initial guess for the unknown parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icepack.statistics import StatisticsProblem, MaximumProbabilityEstimator\n",
    "\n",
    "problem = StatisticsProblem(\n",
    "    simulation=simulation,\n",
    "    loss_functional=loss_functional,\n",
    "    regularization=regularization,\n",
    "    controls=z,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've specified the problem, we'll create a `MaximumProbabilityEstimator` to look for a solution.\n",
    "The runtime is about the same as in the previous demo, so feel free to put on a fresh pot of coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MaximumProbabilityEstimator(\n",
    "    problem,\n",
    "    gradient_tolerance=1e-4,\n",
    "    step_tolerance=1e-1,\n",
    "    max_iterations=50,\n",
    ")\n",
    "z = estimator.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the algorithm reduces the objective by two orders of magnitude by the time it's converged.\n",
    "The computed log-fluidity field looks very similar to the one obtained when we matched the computed velocity to the field obtained by interpolating the observations to the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots()\n",
    "colors = firedrake.tripcolor(z.subfunctions[0], vmin=-5, vmax=+5, axes=axes)\n",
    "fig.colorbar(colors);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "firedrake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
